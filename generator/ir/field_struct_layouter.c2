/* Copyright 2022-2025 Bas van den Berg
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

module ir_generator;

import ast;
import ctv_analyser;
import ir local;
import ir_context;

import std;

type FieldInit struct {
    const ast.FieldInitField* info;
    ast.Expr* expr;
}
static_assert(16, sizeof(FieldInit));

type FieldStructLayouter struct {
    Generator* gen;
    u32 size;

    FieldInit* inits;
    u32 num_inits;
    u32 max_inits;
}

fn void FieldStructLayouter.init(FieldStructLayouter* l,
                                     Generator* gen,
                                     u32 struct_size,
                                     u32 num_members) {
    l.gen = gen;
    l.size = struct_size;
    l.num_inits = 0;
    l.inits = nil;
    l.resize(num_members);
}

fn void FieldStructLayouter.resize(FieldStructLayouter* l, u32 max) {
    l.max_inits = max;
    FieldInit* inits = std.malloc(max * sizeof(FieldInit));
    if (l.num_inits) std.memcpy(inits, l.inits, l.num_inits * sizeof(FieldInit));
    if (l.inits) std.free(l.inits);
    l.inits = inits;
}

fn void FieldStructLayouter.add(FieldStructLayouter* l,
                                const ast.FieldInitField* info,
                                ast.Expr* value) {
    if (l.num_inits == l.max_inits) l.resize(l.max_inits * 2);

    FieldInit init;
    init.info = info;
    init.expr = value;

    if (l.num_inits == 0) {
        l.inits[0] = init;
        l.num_inits = 1;
        return;
    }

    // insert sorted
    u32 idx = l.num_inits;
    u32 offset = info.offset;
    while (idx) {
        FieldInit* fi = &l.inits[idx-1];
        //if (offset > fi.info.offset) break;
        if (info.member_idx >= fi.info.member_idx) break;
        l.inits[idx] = *fi; // move up
        idx--;
    }
    l.inits[idx] = init;
    l.num_inits++;
}

// Note: finalize is used for GLOBALS and does initialize padding
fn void FieldStructLayouter.finalize(FieldStructLayouter* l) {
    u32 cur_offset = 0;
    bool have_bitfield = false;
    u8 bitfield_base_size = 0;   // in bytes of whole field
    u64 bitfield_value = 0; // will be downsized to correct size later

    // Iterator all members, check if there is an init, otherwise init to 0
    // Generate init for all fields
    for (u32 i=0; i<l.num_inits; i++) {
        const FieldInit* fi = &l.inits[i];
        const ast.Expr* e = fi.expr;
        ast.QualType qt = e.getType();
        u32 size = qt.getSize(false);
        // TODO dont get from type, already set is Layout

        // TODO merge bit-fields and/or other CTV fields

        //printf("[%d] off %d/%d  bit %d\n", i, cur_offset, fi.info.offset, have_bitfield);
        u32 pad = fi.info.offset - cur_offset;   // means offsets have changed
        if (pad) {
            //printf("FIELD offset %d -> %d\n", cur_offset, fi.info.offset);
            if (have_bitfield) {
                //printf("  outstanding bitfield (size %d)\n", bitfield_base_size);
                l.gen.emitBitfield(bitfield_base_size, bitfield_value);
                cur_offset += bitfield_base_size;
                pad -= bitfield_base_size;
                have_bitfield = false;
                bitfield_value = 0;
                bitfield_base_size = 0;
                if (!pad) goto field;
            }
            assert(fi.info.offset > cur_offset);
            //printf("PAD1 %d\n", pad);
            l.gen.ctx.addInitZero(pad);
            cur_offset = fi.info.offset;
        }
field:

        if (fi.info.is_bitfield) {
            have_bitfield = true;
            bitfield_base_size = (u8)fi.info.bitfield_base_size;

            //printf("BITFIELD(%d, %d) size %d\n", fi.info.bitfield_offset, fi.info.bitfield_width, bitfield_base_size);

            if (e.isCtv()) {
                ast.Value value = ctv_analyser.get_value(e);
                value.mask(fi.info.bitfield_width);
                value.left_shift2(fi.info.bitfield_offset);
                u64 v = value.as_u64();
                bitfield_value |= v;
                //printf("  Value 0x%x  => %x\n", v, bitfield_value);
            } else {
                assert(0);  // TODO
            }
        } else {
            l.gen.emitInit(e, size);
            cur_offset = fi.info.offset + size;
        }
    }

    if (have_bitfield) {
        //printf("END flush bitfield (%d)\n", bitfield_base_size);
        l.gen.emitBitfield(bitfield_base_size, bitfield_value);
        cur_offset += bitfield_base_size;
    }

    // emit final padding
    if (cur_offset != l.size) {
        assert(l.size > cur_offset);
        u32 pad = l.size - cur_offset;
        //printf("PAD2 %d (size %d off %d)\n", pad, l.size, cur_offset);
        l.gen.ctx.addInitZero(pad);
    }

    std.free(l.inits);
}

// Note: finalizeExpr is used for non-GLOBALS and does NOT initialize padding
fn void FieldStructLayouter.finalizeExpr(FieldStructLayouter* l, const ast.StructTypeDecl* sd, Ref base_ref) {
    bool have_bitfield = false;
    u8 bitfield_base_size = 0;   // in bytes of whole field
    ir_context.Context* ctx = l.gen.ctx;

    u32 num_members = sd.getNumMembers();
    ast.StructLayout* layout = sd.getLayout();

    // TODO can also be {}, 0 inits
    //printf("num_inits %d  num_members %d\n", l.num_inits, num_members);
    u32 init_idx = 0;
    u32 cur_offset = 0;
    const FieldInit* fi = &l.inits[init_idx];
    Ref dest_ref = base_ref;

    for (u32 i = 0; i < num_members; i++) {
        const ast.StructMemberLayout* ml = &layout.members[i];
        //printf(" [%d|%d] offset %d  size %d\n", i, init_idx, ml.offset, ml.size);

        if (ml.is_bitfield) {
            //printf("member idx %d\n", fi.info.member_idx);
            if (init_idx < l.num_inits && fi.info.member_idx == i) {
                ir.Type t = size2type(ml.size);
                ast.Expr* e = fi.expr;
                Ref value_ref;
                if (e.isCtv()) {
                    ast.Value value = ctv_analyser.get_value(e);
                    value.mask(fi.info.bitfield_width);
                    if (fi.info.bitfield_offset) value.left_shift2(fi.info.bitfield_offset);
                    u64 v = value.as_u64();

                    // TODO handle 64-bit bitfields
                    value_ref = ctx.addIntegerConstant((i64)v);
                } else {
                    l.gen.emitExpr(&value_ref, e);
                    // mask
                    Ref mask_value = ctx.addIntegerConstant((1 << ml.bitfield_width) -1);
                    value_ref = ctx.addBinaryInstr(InstrKind.And, mask_value, value_ref);
                    // shift (if needed)
                    if (ml.bitfield_offset) {
                        Ref shift_value = ctx.addIntegerConstant(ml.bitfield_offset);
                        value_ref = ctx.addBinaryInstr(InstrKind.Shl, shift_value, value_ref);
                    }
                }
                if (!have_bitfield) { // generate SET
                    ctx.addStoreInstr(t, value_ref, dest_ref);
                } else { // generate OR
                    Ref bitfield_ref = ctx.addLoadInstr(t, dest_ref);
                    bitfield_ref = ctx.addBinaryInstr(InstrKind.Or, bitfield_ref, value_ref);
                    ctx.addStoreInstr(t, bitfield_ref, dest_ref);
                }

                init_idx++;
                fi = &l.inits[init_idx];
            } else {
                // TODO init entire field to 0 if not initialized at all
            }

            //printf(" [%d] bitfield w %d s %d\n", i, fi.info.bitfield_width, fi.info.bitfield_offset);
            // TODO if all bitfields CTV, merge (separate from whole InitListExpr CTC)
            // TODO need to increment offset if needed
            if (!have_bitfield) have_bitfield = true;
            continue;
            // if last member, always emit bitfields
        } else {
            if (have_bitfield) {
                // flush bitfield
                // TODO
                have_bitfield = false;
            }
        }

        if (ml.offset != 0) {
            Ref offset_ref = ctx.addIntegerConstant(ml.offset - cur_offset);
            cur_offset = ml.offset;
            dest_ref = ctx.addBinaryInstr(InstrKind.Add, dest_ref, offset_ref);
        }

        Ref value_ref;
        if (init_idx < l.num_inits && fi.info.member_idx == i) {
            //printf("  have init\n");
            l.gen.emitExpr(&value_ref, fi.expr);

            init_idx++;
            fi = &l.inits[init_idx];
        } else {
            value_ref = ctx.addIntegerConstant(0);
        }

        ctx.addStoreInstr(size2type(ml.size), value_ref, dest_ref);
    }

    std.free(l.inits);
}

