/* Copyright 2022-2025 Bas van den Berg
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

module c2cat_main;

import c2_tokenizer;
import color;
import file_utils;
import keywords;
import src_loc local;
import string_buffer;
import string_list;
import string_pool;
import number_radix;
import token local;

import stdio local;
import stdlib local;
import string local;

type Style enum u8 {
    Normal,
    Identifier,
    Integer,
    Float,
    Charconst,
    String,
    Operator,
    Type,
    Keyword,
    Function,
    Attr,
    Feature,
    Invalid,
    Comment,
    Warning,
    Error,
}

fn void usage(const char* me) {
    printf("Usage: %s [options] file.c2 ...\n"
           "    --color      force colorized output\n"
           "    --nocolor    disable colorized output\n"
           , me);
    exit(1);
}

type C2cat struct {
    string_pool.Pool* pool;
    c2_tokenizer.Tokenizer* tokenizer;
    const char* input;
    u32 offset;
    u32 length;
    string_buffer.Buf* out;
    u8 in_attributes; // 0 no, 1 seen @, 2 (, ) -> 0
    bool has_error;
    Style* token_style;
    const char** style_color;
}

const char*[] attr_names = {
    "export",
    "packed",
    "unused",
    "unused_params",
    "section",
    "noreturn",
    "inline",
    "printf_format",
    "aligned",
    "weak",
    "opaque",
    "cname",
    "no_typedef",
    "constructor",
    "destructor",
    "pure",
    "auto_file",
    "auto_line",
    "auto_func",
}

const char*[] default_colors = {
    [Style.Normal] = color.Normal,
    [Style.Identifier] = "",
    [Style.Integer] = color.Magenta,
    [Style.Float] = color.Magenta,
    [Style.Charconst] = color.Magenta,
    [Style.String] = color.Magenta,
    [Style.Operator] = "",
    [Style.Type] = color.Green,
    [Style.Keyword] = color.Byellow,
    [Style.Function] = color.White,
    [Style.Attr] = color.Blue,
    [Style.Feature] = color.Blue,
    [Style.Invalid] = color.Bred,
    [Style.Comment] = color.Bcyan,
    [Style.Warning] = color.Bred,
    [Style.Error] = color.Bred,
}

const char*[] style_names = {
    [Style.Normal] = "normal",
    [Style.Identifier] = "identifier",
    [Style.Integer] = "integer",
    [Style.Float] = "float",
    [Style.Charconst] = "charconst",
    [Style.String] = "string",
    [Style.Operator] = "operator",
    [Style.Type] = "type",
    [Style.Keyword] = "keyword",
    [Style.Function] = "function",
    [Style.Attr] = "attr",
    [Style.Feature] = "feature",
    [Style.Invalid] = "invalid",
    [Style.Comment] = "comment",
    [Style.Warning] = "warning",
    [Style.Error] = "error",
}

fn bool init_colors(Style* token_style, const char** style_color) {
    for (Kind k = Kind.min; k <= Kind.max; k++) {
        Style style = Normal;
        switch (k) {
        case None:
            style = Normal;
            break;
        case Identifier:
            style = Identifier;
            break;
        case IntegerLiteral:
            style = Integer;
            break;
        case FloatLiteral:
            style = Float;
            break;
        case CharLiteral:
            style = Charconst;
            break;
        case StringLiteral:
            style = String;
            break;
        case LParen ... GreaterGreaterEqual:
            style = Operator;
            break;
        case KW_bool ... KW_void:
            style = Type;
            break;
        case KW_as ... KW_while:
            if (k.isQualifier()) style = Type;
            else style = Keyword;
            break;
        case Feat_if ... Feat_warning:
            style = Feature;
            break;
        case Invalid:
            style = Invalid;
            break;
        case LineComment:
        case BlockComment:
            style = Comment;
            break;
        case Eof:
            style = Normal;
            break;
        case Warning:
            style = Warning;
            break;
        case Error:
            style = Error;
            break;
        }
        token_style[k] = style;
    }
    for (Style s = Style.min; s <= Style.max; s++) {
        style_color[s] = color.getConfigColor(style_names[s], default_colors[s]);
    }
    return color.useColor();
}

fn bool C2cat.is_attribute(C2cat* ctx, u32 name_idx) {
    const char* str = ctx.pool.idx2str(name_idx);
    for (u32 i = 0; i < elemsof(attr_names); i++) {
        if (strcmp(str, attr_names[i]) == 0) return true;
    }
    return false;
}

fn void C2cat.update_state(C2cat* ctx, const Token* tok) {
    switch (ctx.in_attributes) {
    case 0:
        if (tok.kind == Kind.At) ctx.in_attributes = 1;
        break;
    case 1:
        if (tok.kind == Kind.LParen) ctx.in_attributes = 2;
        break;
    case 2:
        if (tok.kind == Kind.RParen) ctx.in_attributes = 0;
        break;
    }
}

fn void C2cat.print_token(C2cat* ctx, const Token* tok) {
    string_buffer.Buf* out = ctx.out;
    u32 pos = tok.loc - ctx.tokenizer.loc_start;    // token start offset
    u32 tok_len = tok.len;                          // token length in bytes

    if (pos < ctx.offset) {
        // token starts before end of previous token, this is an error
        // TODO: output an error message to stderr?
        out.add1('\n');
        out.color(ctx.style_color[Style.Error]);
        out.print("error: offset=%d pos=%d", ctx.offset, pos);
        out.color(ctx.style_color[Style.Normal]);
        out.add1('\n');
        ctx.offset = pos;
    }
    if (pos > ctx.offset) {
        // copy stuff from file to out (from end of last token to start of current)
        // TODO: check for whitespace only
        out.add2(ctx.input + ctx.offset, pos - ctx.offset);
        ctx.offset = pos;
    }

    Style s = ctx.token_style[tok.kind];
    if (tok.kind == Kind.Identifier) {
        if (ctx.in_attributes && ctx.is_attribute(tok.name_idx)) {
            s = Style.Attr;
        } else
        if (ctx.input[ctx.offset + tok_len] == '(') {
            s = Style.Function;
        }
    }
    if (s) {
        out.color(ctx.style_color[s]);
    }
    out.add2(ctx.input + ctx.offset, tok_len);

    if (s && *ctx.style_color[s]) {
        out.color(ctx.style_color[Style.Normal]);
    }
    ctx.offset += tok_len;
}

fn void C2cat.on_tokenizer_error(void* arg, SrcLoc loc) {
    C2cat* ctx = arg;
    ctx.has_error = true;
}

fn i32 c2cat(const char* filename,
             bool use_color,
             Style* token_style,
             const char** style_color)
{
    file_utils.File file.init("", filename);
    if (!file.load()) {
        fprintf(stderr, "error opening %s: %s\n", filename, file.getError());
        return -1;
    }

    string_pool.Pool* pool = string_pool.create(16*1024, 1024);
    string_buffer.Buf* buf = string_buffer.create(1024, false, 0);
    const char* input = file.data();
    u32 file_size = file.data_size();
    keywords.Info kwinfo.init(pool);
    string_list.List features.init(pool);
    string_buffer.Buf* out = string_buffer.create(16*1024, use_color, 2);

    C2cat ctx = {
        .pool = pool,
        .input = input,
        .offset = 0,
        .length = file_size,
        .out = out,
        .in_attributes = 0,
        .token_style = token_style,
        .style_color = style_color,
    }

    c2_tokenizer.Tokenizer tokenizer.init(pool, buf, input, 1, &kwinfo, &features,
                                          C2cat.on_tokenizer_error, C2cat.on_tokenizer_error, &ctx, true);
    ctx.tokenizer = &tokenizer;

    Token tok.init();

    while (!tok.done) {
        tokenizer.lex(&tok);
        if (ctx.has_error) {
            tok.kind = Error;
            ctx.has_error = false;
        }
        ctx.update_state(&tok);
        ctx.print_token(&tok);
    }

    if (ctx.offset <= ctx.length) {
        // TODO: EOF token should have ctx.offset == ctx.length
        u32 len = ctx.length - ctx.offset;
        if (len) {
            out.color(style_color[Style.Error]);
            out.add2(ctx.input + ctx.offset, len);
            out.color(style_color[Style.Normal]);
        }
    } else {
        out.add1('\n');
        out.color(style_color[Style.Error]);
        out.print("error: offset=%d file.size=%d", ctx.offset, ctx.length);
        out.color(style_color[Style.Normal]);
        out.add1('\n');
    }
    fputs(out.data(), stdout);
    fflush(stdout);

    out.free();
    buf.free();
    pool.free();
    file.close();

    return 0;
}

public fn i32 main(i32 argc, const char** argv)
{
    Style[elemsof(Kind)] token_style;
    const char*[elemsof(Style)] style_color;
    // TODO: use custom colors
    bool use_color = init_colors(token_style, style_color);
    i32 filenum = 0;
    i32 nfiles = 0;
    for (i32 i = 1; i < argc; i++) {
        nfiles += (*argv[i] != '-');
    }
    for (i32 i = 1; i < argc; i++) {
        const char* arg = argv[i];
        if (*arg == '-') {
            switch (arg) {
            case "--color":
                use_color = true;
                break;
            case "--nocolor":
                use_color = false;
                break;
            case "-?":
            case "-h":
            case "--help":
                usage(argv[0]);
                break;
            default:
                fprintf(stderr, "c2cat: unknown option %s\n", arg);
                exit(EXIT_FAILURE);
            }
        } else {
            if (nfiles > 1) {
                if (filenum++) printf("\n");
                printf("==> %s <==\n", arg);
            }
            c2cat(arg, use_color, token_style, style_color);
        }
    }
    if (!nfiles) usage(argv[0]);
    return 0;
}
