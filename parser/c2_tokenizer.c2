/* Copyright 2022-2023 Bas van den Berg
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

module c2_tokenizer;

import constants;
import src_loc local;
import string_buffer;
import string_list;
import string_pool;
import token local;

import string;
import stdlib;
import ctype local;
import stdarg local;

import stdio;

public const u32 MaxLookahead = 16;  // must be multiple of 2

type Keyword struct {
    const char* name;
    Kind kind;
    u8 len;
}

// Note: index is alphabet
const Keyword*[] keywords = {
    Keywords_a,
    Keywords_b,
    Keywords_c,
    Keywords_d,
    Keywords_e,
    Keywords_f,
    Keywords_g,
    nil,
    Keywords_i,
    nil,
    nil,
    Keywords_l,
    Keywords_m,
    Keywords_n,
    Keywords_o,
    Keywords_p,
    nil,
    Keywords_r,
    Keywords_s,
    Keywords_t,
    Keywords_u,
    Keywords_v,
    Keywords_w,
    nil,
    nil,
    nil,
}

const Keyword[] Keywords_a = {
    { "as",         Kind.KW_as,         2 },
    { "asm",        Kind.KW_asm,        3 },
    { "assert",     Kind.KW_assert,     6 },
    { nil,          Kind.None,          0 },
}
const Keyword[] Keywords_b = {
    { "bool",       Kind.KW_bool,       4 },
    { "break",      Kind.KW_break,      5 },
    { nil,          Kind.None,          0 },
}
const Keyword[] Keywords_c = {
    { "case",       Kind.KW_case,       4 },
    { "cast",       Kind.KW_cast,       4 },
    { "char",       Kind.KW_char,       4 },
    { "const",      Kind.KW_const,      5 },
    { "continue",   Kind.KW_continue,   8 },
    { nil,          Kind.None,          0 },
}
const Keyword[] Keywords_d = {
    { "default",    Kind.KW_default,    7 },
    { "do",         Kind.KW_do,         2 },
    { nil,          Kind.None,          0 },
}
const Keyword[] Keywords_e = {
    { "elemsof",    Kind.KW_elemsof,    7 },
    { "else",       Kind.KW_else,       4 },
    { "enum",       Kind.KW_enum,       4 },
    { "enum_max",   Kind.KW_enum_max,   8 },
    { "enum_min",   Kind.KW_enum_min,   8 },
    { nil,          Kind.None,          0 },
}
const Keyword[] Keywords_f = {
    { "f32",        Kind.KW_f32,        3 },
    { "f64",        Kind.KW_f64,        3 },
    { "fallthrough", Kind.KW_fallthrough, 11 },
    { "false",      Kind.KW_false,      5 },
    { "fn",         Kind.KW_fn,         2 },
    { "for",        Kind.KW_for,        3 },
    { nil,          Kind.None,          0 },
}
const Keyword[] Keywords_g = {
    { "goto",       Kind.KW_goto,       4 },
    { nil,          Kind.None,          0 },
}
const Keyword[] Keywords_i = {
    { "i16",        Kind.KW_i16,        3 },
    { "i32",        Kind.KW_i32,        3 },
    { "i64",        Kind.KW_i64,        3 },
    { "i8",         Kind.KW_i8,         2 },
    { "if",         Kind.KW_if,         2 },
    { "import",     Kind.KW_import,     6 },
    { "isize",      Kind.KW_isize,      5 },
    { nil,          Kind.None,          0 },
}
const Keyword[] Keywords_l = {
    { "local",      Kind.KW_local,      5 },
    { nil,          Kind.None,          0 },
}
const Keyword[] Keywords_m = {
    { "module",     Kind.KW_module,     6 },
    { nil,          Kind.None,          0 },
}
const Keyword[] Keywords_n = {
    { "nil",        Kind.KW_nil,        3 },
    { nil,          Kind.None,          0 },
}
const Keyword[] Keywords_o = {
    { "offsetof",   Kind.KW_offsetof,   8 },
    { nil,          Kind.None,          0 },
}
const Keyword[] Keywords_p = {
    { "public",     Kind.KW_public,     6 },
    { nil,          Kind.None,          0 },
}
const Keyword[] Keywords_r = {
    { "reg16",      Kind.KW_reg16,      5 },
    { "reg32",      Kind.KW_reg32,      5 },
    { "reg64",      Kind.KW_reg64,      5 },
    { "reg8",       Kind.KW_reg8,       4 },
    { "return",     Kind.KW_return,     6 },
    { nil,          Kind.None,          0 },
}
const Keyword[] Keywords_s = {
    { "sizeof",     Kind.KW_sizeof,     6 },
    { "sswitch",    Kind.KW_sswitch,    7 },
    { "static_assert", Kind.KW_static_assert, 13 },
    { "struct",     Kind.KW_struct,     6 },
    { "switch",     Kind.KW_switch,     6 },
    { nil,          Kind.None,          0 },
}
const Keyword[] Keywords_t = {
    { "template",   Kind.KW_template, 8 },
    { "to_container", Kind.KW_to_container, 12 },
    { "true",       Kind.KW_true,       4 },
    { "type",       Kind.KW_type,       4 },
    { nil,          Kind.None,          0 },
}
const Keyword[] Keywords_u = {
    { "u16",        Kind.KW_u16,        3 },
    { "u32",        Kind.KW_u32,        3 },
    { "u64",        Kind.KW_u64,        3 },
    { "u8",         Kind.KW_u8,         2 },
    { "union",      Kind.KW_union,      5 },
    { "usize",      Kind.KW_usize,      5 },
    { nil,          Kind.None,          0 },
}
const Keyword[] Keywords_v = {
    { "void",       Kind.KW_void,       4 },
    { "volatile",   Kind.KW_volatile,   8 },
    { nil,          Kind.None,          0 },
}
const Keyword[] Keywords_w = {
    { "while",      Kind.KW_while,      5 },
    { nil,          Kind.None,          0 },
}

type Action enum u8 {
    TABSPACE,
    IDENT_OR_KEYWORD,
    IDENT,
    DIGIT,
    LPAREN,
    RPAREN,
    LSQUARE,
    RSQUARE,
    NEWLINE,
    EXCLAIM,
    DQUOTE,
    SQUOTE,
    POUND,
    STAR,
    PLUS,
    MINUS,
    COMMA,
    DOT,
    PERCENT,
    SLASH,
    COLON,
    SEMI_COLON,
    LESS,
    EQUAL,
    GREATER,
    QUESTION,
    AT,
    AMP,
    CARET,
    LBRACE,
    RBRACE,
    PIPE,
    TILDE,
    CR,
    EOF,
    INVALID,
}

const Action[128] Char_lookup = {
// 0 - 15
   [  0]  = Action.EOF,
   ['\t'] = Action.TABSPACE,
   ['\n'] = Action.NEWLINE,
   ['\r'] = Action.CR,
// 16 - 31
// 32 - 47
    [' '] = Action.TABSPACE,
    ['!'] = Action.EXCLAIM,
    ['"'] = Action.DQUOTE,
    ['#'] = Action.POUND,
    ['%'] = Action.PERCENT,
    ['&'] = Action.AMP,
   ['\''] = Action.SQUOTE,
    ['('] = Action.LPAREN,
    [')'] = Action.RPAREN,
    ['*'] = Action.STAR,
    ['+'] = Action.PLUS,
    [','] = Action.COMMA,
    ['-'] = Action.MINUS,
    ['.'] = Action.DOT,
    ['/'] = Action.SLASH,
// 48 - 63
    ['0'] = Action.DIGIT,
    ['1'] = Action.DIGIT,
    ['2'] = Action.DIGIT,
    ['3'] = Action.DIGIT,
    ['4'] = Action.DIGIT,
    ['5'] = Action.DIGIT,
    ['6'] = Action.DIGIT,
    ['7'] = Action.DIGIT,
    ['8'] = Action.DIGIT,
    ['9'] = Action.DIGIT,
    [':'] = Action.COLON,
    [';'] = Action.SEMI_COLON,
    ['<'] = Action.LESS,
    ['='] = Action.EQUAL,
    ['>'] = Action.GREATER,
    ['?'] = Action.QUESTION,
// 64 - 79
    ['@'] = Action.AT,
    ['A'] = Action.IDENT,
    ['B'] = Action.IDENT,
    ['C'] = Action.IDENT,
    ['D'] = Action.IDENT,
    ['E'] = Action.IDENT,
    ['F'] = Action.IDENT,
    ['G'] = Action.IDENT,
    ['H'] = Action.IDENT,
    ['I'] = Action.IDENT,
    ['J'] = Action.IDENT,
    ['K'] = Action.IDENT,
    ['L'] = Action.IDENT,
    ['M'] = Action.IDENT,
    ['N'] = Action.IDENT,
    ['O'] = Action.IDENT,
// 80 - 95
    ['P'] = Action.IDENT,
    ['Q'] = Action.IDENT,
    ['R'] = Action.IDENT,
    ['S'] = Action.IDENT,
    ['T'] = Action.IDENT,
    ['U'] = Action.IDENT,
    ['V'] = Action.IDENT,
    ['W'] = Action.IDENT,
    ['X'] = Action.IDENT,
    ['Y'] = Action.IDENT,
    ['Z'] = Action.IDENT,
    ['['] = Action.LSQUARE,
    ['\\'] = Action.TABSPACE, // only in skipped parts, treat as whitespace
    [']'] = Action.RSQUARE,
    ['^'] = Action.CARET,
    ['_'] = Action.IDENT,   // for parsing libs
// 96 - 111
    ['a'] = Action.IDENT_OR_KEYWORD,
    ['b'] = Action.IDENT_OR_KEYWORD,
    ['c'] = Action.IDENT_OR_KEYWORD,
    ['d'] = Action.IDENT_OR_KEYWORD,
    ['e'] = Action.IDENT_OR_KEYWORD,
    ['f'] = Action.IDENT_OR_KEYWORD,
    ['g'] = Action.IDENT_OR_KEYWORD,
    ['h'] = Action.IDENT,
    ['i'] = Action.IDENT_OR_KEYWORD,
    ['j'] = Action.IDENT,
    ['k'] = Action.IDENT,
    ['l'] = Action.IDENT_OR_KEYWORD,
    ['m'] = Action.IDENT_OR_KEYWORD,
    ['n'] = Action.IDENT_OR_KEYWORD,
    ['o'] = Action.IDENT_OR_KEYWORD,
// 112 -] 127
    ['p'] = Action.IDENT_OR_KEYWORD,
    ['q'] = Action.IDENT,
    ['r'] = Action.IDENT_OR_KEYWORD,
    ['s'] = Action.IDENT_OR_KEYWORD,
    ['t'] = Action.IDENT_OR_KEYWORD,
    ['u'] = Action.IDENT_OR_KEYWORD,
    ['v'] = Action.IDENT_OR_KEYWORD,
    ['w'] = Action.IDENT_OR_KEYWORD,
    ['x'] = Action.IDENT,
    ['y'] = Action.IDENT,
    ['z'] = Action.IDENT,
    ['{'] = Action.LBRACE,
    ['|'] = Action.PIPE,
    ['}'] = Action.RBRACE,
    ['~'] = Action.TILDE,
}

const u8[128] Identifier_char = {
    ['0'] = 1,
    ['1'] = 1,
    ['2'] = 1,
    ['3'] = 1,
    ['4'] = 1,
    ['5'] = 1,
    ['6'] = 1,
    ['7'] = 1,
    ['8'] = 1,
    ['9'] = 1,
    ['A'] = 1,
    ['B'] = 1,
    ['C'] = 1,
    ['D'] = 1,
    ['E'] = 1,
    ['F'] = 1,
    ['G'] = 1,
    ['H'] = 1,
    ['I'] = 1,
    ['J'] = 1,
    ['K'] = 1,
    ['L'] = 1,
    ['M'] = 1,
    ['N'] = 1,
    ['O'] = 1,
    ['P'] = 1,
    ['Q'] = 1,
    ['R'] = 1,
    ['S'] = 1,
    ['T'] = 1,
    ['U'] = 1,
    ['V'] = 1,
    ['W'] = 1,
    ['X'] = 1,
    ['Y'] = 1,
    ['Z'] = 1,
    ['_'] = 1,
    ['a'] = 1,
    ['b'] = 1,
    ['c'] = 1,
    ['d'] = 1,
    ['e'] = 1,
    ['f'] = 1,
    ['g'] = 1,
    ['h'] = 1,
    ['i'] = 1,
    ['j'] = 1,
    ['k'] = 1,
    ['l'] = 1,
    ['m'] = 1,
    ['n'] = 1,
    ['o'] = 1,
    ['p'] = 1,
    ['q'] = 1,
    ['r'] = 1,
    ['s'] = 1,
    ['t'] = 1,
    ['u'] = 1,
    ['v'] = 1,
    ['w'] = 1,
    ['x'] = 1,
    ['y'] = 1,
    ['z'] = 1,
}

fn const Keyword* check_keyword(const char* cp) {
    const Keyword* table = keywords[*cp - 'a'];
    u32 i = 0;
    while (table[i].name) {
        const char* word = cp;
        const char* kw = table[i].name;
        u32 idx = 0;
        while (1) {
            char a = kw[idx];
            char b = word[idx];
            if (a == 0) {
                if (!Identifier_char[b]) return &table[i];
                break;
            }
            if (a != b) {
                if (b < a) return nil;
                break;
            }
            idx++;
        }
        i++;
    }

    return nil;
}

public type Feature struct {
    bool is_if;
    bool enabled;
}

public type Tokenizer struct {
    const char* cur;
    SrcLoc loc_start;
    const char* input_start;

    Token[MaxLookahead] next;
    u32 next_count;
    u32 next_head;  // index of next token (circular index into next)
    const char* line_start;

    string_pool.Pool* pool; // no ownership
    string_buffer.Buf* buf; // no ownership, used for multi-strings: "a" "b" "c"

    // Feature handling
    Feature[constants.MaxFeatureDepth] feature_stack;
    u32 feature_count;
    const string_list.List* features;
    bool raw_mode;  // also emit comments

    char[256] error_msg;
}

public fn void Tokenizer.init(Tokenizer* t,
                                string_pool.Pool* pool,
                                string_buffer.Buf* buf,
                                const char* input,
                                SrcLoc loc_start,
                                const string_list.List* features,
                                bool raw_mode)
{
    string.memset(t, 0, sizeof(Tokenizer));
    t.cur = input;
    t.input_start = input;
    t.loc_start = loc_start;
    t.line_start = input;
    t.pool = pool;
    t.buf = buf;
    t.features = features;
    t.raw_mode = raw_mode;
    for (u32 i=0; i<MaxLookahead; i++) {
        t.next[i].init();
    }
}

public fn void Tokenizer.lex(Tokenizer* t, Token* result) {
    if (t.next_count) {
        string.memcpy(result, &t.next[t.next_head], sizeof(Token));

        t.next_head = (t.next_head + 1) % MaxLookahead;
        t.next_count--;
        return;
    }
    t.lex_internal(result);
}

fn void Tokenizer.lex_internal(Tokenizer* t, Token* result) {
    // TODO if end/error stop (dont retry) (t.done = 1)

    while (1) {
        Action act = Char_lookup[*t.cur];
        if (t.cur[0] < 0) {
            t.error(result, "Unicode (UTF-8) is only allowed inside string literals or comments");
            return;
        }
        switch (act) {
        case TABSPACE:
            t.cur++;
            continue;
        case IDENT_OR_KEYWORD:
            result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start);
            const Keyword* kw = check_keyword(t.cur);
            if (kw) {
                result.kind = kw.kind;
                t.cur += kw.len;
            } else {
                t.lex_identifier(result);
            }
            return;
        case IDENT:
            t.lex_identifier(result);
            return;
        case DIGIT:
            t.lex_number(result);
            return;
        case LPAREN:
            result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start);
            result.kind = Kind.LParen;
            t.cur++;
            return;
        case RPAREN:
            result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start);
            result.kind = Kind.RParen;
            t.cur++;
            return;
        case LSQUARE:
            result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start);
            result.kind = Kind.LSquare;
            t.cur++;
            return;
        case RSQUARE:
            result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start);
            result.kind = Kind.RSquare;
            t.cur++;
            return;
        case NEWLINE:
            t.cur++;
            t.line_start = t.cur;
            continue;
        case EXCLAIM:
            result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start);
            t.cur++;
            if (*t.cur == '=') {
                result.kind = Kind.ExclaimEqual;
                t.cur++;
            } else {
                result.kind = Kind.Exclaim;
            }
            return;
        case DQUOTE:
            t.lex_string_literal(result);
            return;
        case SQUOTE:
            t.lex_char_literal(result);
            return;
        case POUND:
            if (t.lex_feature_cmd(result)) return;
            if (!t.is_enabled()) {
                if (t.skip_feature(result)) return;
            }
            continue;
        case STAR:
            result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start);
            t.cur++;
            if (*t.cur == '=') {
                result.kind = Kind.StarEqual;
                t.cur++;
            } else {
                result.kind = Kind.Star;
            }
            return;
        case PLUS:
            result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start);
            t.cur++;
            if (*t.cur == '+') {
                t.cur++;
                result.kind = Kind.PlusPlus;
                return;
            }
            if (*t.cur == '=') {
                t.cur++;
                result.kind = Kind.PlusEqual;
                return;
            }
            result.kind = Kind.Plus;
            return;
        case MINUS:
            result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start);
            t.cur++;
            if (*t.cur == '-') {
                t.cur++;
                result.kind = Kind.MinusMinus;
                return;
            }
            if (*t.cur == '=') {
                t.cur++;
                result.kind = Kind.MinusEqual;
                return;
            }
            if (*t.cur == '>') {
                t.cur--;
                t.error(result, "use the dot operators instead of '->'");
                return;
            }
            result.kind = Kind.Minus;
            return;
        case COMMA:
            result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start);
            result.kind = Kind.Comma;
            t.cur++;
            return;
        case DOT:
            result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start);
            t.cur++;
            if (t.cur[0] == '.' && t.cur[1] == '.') {
                t.cur += 2;
                result.kind = Kind.Ellipsis;
            } else {
                result.kind = Kind.Dot;
            }
            return;
        case PERCENT:
            result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start);
            t.cur++;
            if (*t.cur == '=') {
                result.kind = Kind.PercentEqual;
                t.cur++;
            } else {
                result.kind = Kind.Percent;
            }
            return;
        case SLASH:
            result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start);
            t.cur++;
            if (*t.cur == '=') {
                result.kind = Kind.SlashEqual;
                t.cur++;
                return;
            }
            if (*t.cur == '/') {
                if (t.lex_line_comment(result)) return;
                continue;
            }
            if (*t.cur == '*') {
                if (t.lex_block_comment(result)) return;
                continue;
            }
            result.kind = Kind.Slash;
            return;
        case COLON:
            result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start);
            result.kind = Kind.Colon;
            t.cur++;
            return;
        case SEMI_COLON:
            result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start);
            result.kind = Kind.Semicolon;
            t.cur++;
            return;
        case LESS:
            result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start);
            t.cur++;
            if (*t.cur == '=') {
                t.cur++;
                result.kind = Kind.LessEqual;
                return;
            }
            if (*t.cur == '<') {
                t.cur++;
                if (*t.cur == '=') {
                    t.cur++;
                    result.kind = Kind.LessLessEqual;
                } else {
                    result.kind = Kind.LessLess;
                }
                return;
            }
            result.kind = Kind.Less;
            return;
        case EQUAL:
            result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start);
            t.cur++;
            if (*t.cur == '=') {
                result.kind = Kind.EqualEqual;
                t.cur++;
            } else {
                result.kind = Kind.Equal;
            }
            return;
        case GREATER:
            result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start);
            t.cur++;
            if (*t.cur == '=') {
                t.cur++;
                result.kind = Kind.GreaterEqual;
                return;
            }
            if (*t.cur == '>') {
                t.cur++;
                if (*t.cur == '=') {
                    t.cur++;
                    result.kind = Kind.GreaterGreaterEqual;
                } else {
                    result.kind = Kind.GreaterGreater;
                }
                return;
            }
            result.kind = Kind.Greater;
            return;
        case QUESTION:
            result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start);
            result.kind = Kind.Question;
            t.cur++;
            return;
        case AT:
            result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start);
            result.kind = Kind.At;
            t.cur++;
            return;
        case AMP:
            result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start);
            t.cur++;
            if (*t.cur == '&') {
                result.kind = Kind.AmpAmp;
                t.cur++;
                return;
            }
            if (*t.cur == '=') {
                result.kind = Kind.AmpEqual;
                t.cur++;
                return;
            }
            result.kind = Kind.Amp;
            return;
        case CARET:
            result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start);
            t.cur++;
            if (*t.cur == '=') {
                t.cur++;
                result.kind = Kind.CaretEqual;
                return;
            }
            result.kind = Kind.Caret;
            return;
        case LBRACE:
            result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start);
            result.kind = Kind.LBrace;
            t.cur++;
            return;
        case RBRACE:
            result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start);
            result.kind = Kind.RBrace;
            t.cur++;
            return;
        case PIPE:
            result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start);
            t.cur++;
            if (*t.cur == '|') {
                result.kind = Kind.PipePipe;
                t.cur++;
                return;
            }
            if (*t.cur == '=') {
                result.kind = Kind.PipeEqual;
                t.cur++;
                return;
            }
            result.kind = Kind.Pipe;
            return;
        case TILDE:
            result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start);
            result.kind = Kind.Tilde;
            t.cur++;
            return;
        case CR:
            t.cur++;
            if (*t.cur != '\n') {
                t.error(result, "unexpected char 0x%02X", *t.cur);
                return;
            }
            t.cur++;
            return;
        case EOF:
            // point to last byte in file
            result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start) -1;
            result.kind = Kind.Eof;
            result.more = false;
            return;
        case INVALID:
            t.error(result, "invalid char '%c'", *t.cur);
            return;
        }
    }
}

public fn Token Tokenizer.lookahead(Tokenizer* t, u32 n) {
    assert(n > 0);
    assert(n <= MaxLookahead);
    while (t.next_count < n) {
        const u32 slot = (t.next_head + t.next_count) % MaxLookahead;
        t.lex_internal(&t.next[slot]);
        t.next_count++;
    }

    u32 slot = (t.next_head + n - 1) % MaxLookahead;
    return t.next[slot];
}

fn void Tokenizer.error(Tokenizer* t, Token* result, const char* format @(printf_format), ...) {
    Va_list args;
    va_start(args, format);
    vsnprintf(t.error_msg, sizeof(t.error_msg)-1, format, args);
    va_end(args);

    result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start);
    result.kind = Kind.Error;
    result.error_msg = t.error_msg;
    result.more = false;
}

fn void Tokenizer.lex_identifier(Tokenizer* t, Token* result) {
    // NOTE: result.loc are already set
    result.kind = Kind.Identifier;
    result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start);
    const char* start = t.cur;
    const char* end = t.cur + 1;
    while (Identifier_char[*end]) end++;

    usize len = cast<usize>(end - start);
    if (len > constants.MaxIdentifierLen) {
        t.error(result, "identifier too long (max %d chars)", constants.MaxIdentifierLen);
        return;
    }
    t.cur += len;
    result.text_idx = t.pool.add(start, len, true);
}

fn u8 hex2val(char c) {
    if (c >= '0' && c <= '9') return cast<u8>(c - '0');
    if (c >= 'a' && c <= 'f') return cast<u8>(c - 'a');
    return cast<u8>(c - 'A');
}

fn bool is_octal(char c) {
    return (c >= '0' && c <= '7');
}

fn bool is_binary(char c) {
    return (c >= '0' && c <= '1');
}

fn void Tokenizer.lex_number(Tokenizer* t, Token* result) {
    result.kind = Kind.IntegerLiteral;
    result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start);
    const char* start;

    if (t.cur[0] == '0') {
        if (t.cur[1] == 'x') {  // hexadecimal
            result.radix = 16;
            t.cur += 2;
            start = t.cur;
            while (isxdigit(*t.cur)) t.cur++;
            if (isalpha(*t.cur)) {
                t.error(result, "invalid character '%c' in hexadecimal constant", *t.cur);
                return;
            }
            // TODO check max length
            result.int_value = stdlib.strtoull(start, nil, 16);
            return;
        }
        if (is_octal(t.cur[1])) { // octal
            result.radix = 8;
            t.cur++;
            start = t.cur;
            while (is_octal(*t.cur)) t.cur++;
            if (isxdigit(*t.cur)) {
                t.error(result, "invalid digit '%c' in octal constant", *t.cur);
                return;
            }
            result.int_value = stdlib.strtoull(start, nil, 8);
            // TODO check max length
            return;
        }
        if (t.cur[1] == 'b') {   // binary
            result.radix = 2;
            t.cur += 2;
            start = t.cur;
            while (is_binary(*t.cur)) t.cur++;
            if (isdigit(*t.cur)) {
                t.error(result, "invalid digit '%c' in binary constant", *t.cur);
                return;
            }
            result.int_value = stdlib.strtoull(start, nil, 2);
            // TODO check max length
            return;
        }

        if (t.cur[1] == '.') {  // floating point
            t.cur++;    // skip until .
            t.lex_floating_point(result, t.cur);
            return;
        }

        // case for decimal 0
        if (isdigit(t.cur[1])) {
            t.error(result, "decimal numbers may not start with a 0");
            return;
        }

        t.cur++;
        result.radix = 10;
        result.int_value = 0;
        return;
    }
    result.radix = 10;
    start = t.cur;
    while (isdigit(*t.cur)) t.cur++;

    if (t.cur[0] == '.') {
        t.lex_floating_point(result, start);
        return;
    }
    // TODO could be float

    u32 len = cast<u32>(t.cur - start);
    if (len >= 20) {
        if (len > 20 || string.strncmp(start, "18446744073709551615", 20) > 0) {
            t.cur -= len;
            t.error(result, "integer literal is too large to be represented in any integer type");
            return;
        }
    }
    result.int_value = stdlib.strtoull(start, nil, 10);
}

fn void Tokenizer.lex_floating_point(Tokenizer* t, Token* result, const char* start) {
    // Note: t.cur is on '.', start points to start of entire float
    t.cur++; // skip '.'
    result.kind = Kind.FloatLiteral;
    result.loc = t.loc_start + cast<SrcLoc>(start - t.input_start);
    result.float_value = stdlib.strtod(start, nil);

    // TODO also handle exponent (eg. 1234e+4)
    while (isdigit(*t.cur)) t.cur++;
}

// Returns how much to shift in source code (0 = error)
fn u32 Tokenizer.lex_escaped_char(Tokenizer* t, Token* result) {
    // Note: t.cur is on '\'
    const char* input = t.cur + 1;  // skip backspace
    switch (input[0]) {
    case '"':
        result.char_value = '"';
        break;
    case '\'':
        result.char_value = '\'';
        break;
    case '?':
        result.char_value = '\?';
        break;
    case '\\':
        result.char_value = '\\';
        break;
    case 'a':
        result.char_value = '\a';
        break;
    case 'b':
        result.char_value = '\b';
        break;
    case 'f':
        result.char_value = '\f';
        break;
    case 'n':
        result.char_value = '\n';
        break;
    case 'r':
        result.char_value = '\r';
        break;
    case 't':
        result.char_value = '\t';
        break;
    case 'u':
        t.error(result, "unicode escape sequences not supported yet");
        return 0;
    case 'v':
        result.char_value = '\v';
        break;
    case 'x':
        if (!isxdigit(input[1]) || !isxdigit(input[2])) {
            t.cur++;
            t.error(result, "expect hexadecimal number after '\\x'");
            return 0;
        }
        result.char_value = hex2val(input[1]) * 16 + hex2val(input[2]);
        result.radix = 16;
        return 3;
    default:
        if (is_octal(input[0])) {
            u32 offset = 0;
            u32 value = 0;
            while (is_octal(input[offset]) && offset <= 3) {
                value *= 8;
                value += cast<u32>(input[offset] - '0');
                offset++;
            }

            if (value > 127) {
                t.cur++;
                t.error(result, "octal escape sequence out of range");
                return 0;
            }
            result.char_value = cast<u8>(value);
            result.radix = 8;
            return offset;
        }
        t.cur++;
        t.error(result, "unknown escape sequence '\\%c'", input[0]);
        return 0;
    }
    return 1;
}

fn void Tokenizer.lex_char_literal(Tokenizer* t, Token* result) {
    result.kind = Kind.CharLiteral;
    result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start);
    result.radix = 10;

    if (t.cur[1] == '\\') {
        t.cur++; // skip quote
        u32 len = t.lex_escaped_char(result);
        if (len == 0) return;
        t.cur += (len - 1);
    } else {
        result.char_value = cast<u8>(t.cur[1]);
    }

    if (t.cur[2] != '\'') {
        if (t.cur[2] != 0 && t.cur[3] == '\'') {
            t.error(result, "multi-character character constant");
        } else {
            t.error(result, "missing terminating ' character (GOT %c)", t.cur[2]);
            //t.error(result, "missing terminating ' character");
        }
        return;
    }

    t.cur += 3;
}

fn void Tokenizer.lex_string_literal(Tokenizer* t, Token* result) {
    result.kind = Kind.StringLiteral;
    result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start);
    t.cur++; // skip "
    const char* start = t.cur;
    u32 len;
    u32 num_escapes = 0;

    while (1) {
        switch (*t.cur) {
        case 0: fallthrough;
        case '\r': fallthrough;
        case '\n':
            t.cur--;
            t.error(result, "unterminated string");
            return;
        case '\\':
            u32 esc_len = t.lex_escaped_char(result);
            if (esc_len == 0) return;
            num_escapes += esc_len;
            t.cur += (esc_len + 1);
            break;
        case '"':
            goto out;
        default:
            t.cur++;
            break;
        }
    }
out:
    len = cast<u32>(t.cur - start);
    t.cur++;    // skip end delimiter

    // check multi-strings "a" "b" "c", concatenate into single string
    if (!t.raw_mode && t.is_multi_string()) {
        t.buf.clear();
        t.buf.add2(start, len);

        while (1) {
            if (!t.skip_to_next_string(result)) return;

            if (!t.lex_string_literal_multi(result, &num_escapes)) return;

            if (!t.is_multi_string()) break;
        }
        result.text_len = t.buf.size() + 1 - num_escapes;   // include 0-terminator
        result.text_idx = t.pool.add(t.buf.data(), t.buf.size(), false);

    } else {
        result.text_len = len + 1 - num_escapes;   // include 0-terminator
        result.text_idx = t.pool.add(start, len, false);
    }
    // Note: we could put all empty string at index 1 (not 0, since that means nil)
}

fn bool Tokenizer.lex_string_literal_multi(Tokenizer* t, Token* result, u32* num_escapes) {
    u32 len;
    t.cur++;    // skip start delimiter
    const char* start = t.cur;

    while (1) {
        switch (*t.cur) {
        case 0: fallthrough;
        case '\r': fallthrough;
        case '\n':
            t.cur--;
            t.error(result, "unterminated string");
            return false;
        case '\\':
            u32 esc_len = t.lex_escaped_char(result);
            if (esc_len == 0) return false;
            *num_escapes += esc_len;
            t.cur += (esc_len + 1);
            break;
        case '"':
            goto out;
        default:
            t.cur++;
            break;
        }
    }
out:
    len = cast<u32>(t.cur - start);
    t.buf.add2(start, len);
    t.cur++;    // skip end delimiter
    return true;
}

fn bool Tokenizer.lex_line_comment(Tokenizer* t, Token* result) {
    t.cur += 1;
    const char* start = t.cur;
    const char* end = start;

    while (*end) {
        if (*end == '\r' || *end == '\n') break;
        end++;
    }

    u32 len = cast<u32>(end - start);
    t.cur += len;

    if (t.raw_mode) {
        result.kind = Kind.LineComment;
        result.loc = t.loc_start + cast<SrcLoc>(start - t.input_start -2);
        result.text_idx = t.pool.add(start, len, false);
        return true;
    }
    return false;
}

fn bool Tokenizer.lex_block_comment(Tokenizer* t, Token* result) {
    t.cur += 1;
    const char* start = t.cur;
    while (1) {
        switch (*t.cur) {
        case 0:
            t.cur--;
            t.error(result, "un-terminated block comment");
            return true;
        case '/':
            if (t.cur[1] == '*') {
                t.error(result, "'/*' within block comment");
                return true;
            }
            break;
        case '*':
            if (t.cur[1] == '/') {
                t.cur += 2;
                if (t.raw_mode) {
                    usize len = cast<usize>(t.cur - start - 2);
                    result.kind = Kind.BlockComment;
                    result.loc = t.loc_start + cast<SrcLoc>(start - t.input_start - 2);
                    result.text_idx = t.pool.add(start, len, false);
                    return true;
                }
                return false;
            }
            break;
        default:
            break;
        }
        t.cur++;
    }
    return false;
}

fn bool compare_word(const char* cur, const char* expect) {
    while (*expect) {
        if (*cur != *expect) return false;
        cur++;
        expect++;
    }
    return !Identifier_char[*cur];
}

// return true if we pass result
fn bool Tokenizer.lex_feature_cmd(Tokenizer* t, Token* result) {
    if (t.cur != t.line_start) {
        t.error(result, "#if/#else/#endif must be at start of line");
        return true;
    }
/*
    Syntax:
        #if <selection>
        #else
        #endif
        #error "msg"

    later:
        AND OR NOT
        #warn "msg"
*/
    t.cur++;    // skip #

    if (compare_word(t.cur, "if")) {
        t.cur += 2;
        if (t.handle_if(result)) return true;
    } else if (compare_word(t.cur, "else")) {
        t.cur += 4;
        if (t.handle_else(result)) return true;
    } else if (compare_word(t.cur, "endif")) {
        t.cur += 5;
        if (t.handle_endif(result)) return true;
    } else if (compare_word(t.cur, "error")) {
        t.cur += 5;
        if (t.raw_mode) return false; // TODO return token
        return t.parse_error_warn(result, true);
    } else if (compare_word(t.cur, "warn")) {
        t.cur += 4;
        if (t.raw_mode) return false; // TODO return token
        return t.parse_error_warn(result, false);
    } else {
        t.error(result, "unknown feature-selection command");
        return true;
    }
    return false;
}

fn bool Tokenizer.parse_error_warn(Tokenizer* t, Token* result, bool is_error) {
    // NOTE: #warn/#error must always have good syntax, even in dis-abled feature!

    t.cur++;    // skip SPACE
    if (*t.cur != '"') {
        t.error(result, "expect '\"'");
        return true;
    }
    t.cur++;
    const char* start = t.cur;
    while (*t.cur != '\"') {
        switch (*t.cur) {
        case 0: fallthrough;
        case '\r': fallthrough;
        case '\n':
            t.error(result, "unterminated string");
            return true;
        case '\"':
            break;
        default:
            t.cur++;
            break;
        }
    }
    usize len = cast<usize>(t.cur - start);
    t.cur++;
    if (len > constants.MaxIdentifierLen) {
        t.error(result, "error msg too long (max %d bytes)", constants.MaxErrorMsgLen);
        return true;
    }
    char[constants.MaxErrorMsgLen+1] msg;
    string.memcpy(msg, start, len);
    msg[len] = 0;

    if (t.is_enabled()) {
        if (is_error) {
            t.cur = t.line_start;
            t.error(result, "%s", msg);
        } else {
            string.strcpy(t.error_msg, msg);
            result.loc = t.loc_start + cast<SrcLoc>(t.line_start - t.input_start);
            result.kind = Kind.Warning;
            result.error_msg = t.error_msg;
        }
        return true;
    }
    return false;
}

fn bool Tokenizer.is_enabled(const Tokenizer* t) {
    for (u32 i=0; i<t.feature_count; i++) {
        if (!t.feature_stack[i].enabled) return false;
    }
    return true;
}

fn bool Tokenizer.handle_if(Tokenizer* t, Token* result) {
    // Syntax: 0 | 1 | FEATURE | FEATURE=<value>
    if (t.raw_mode) {
        result.kind = Kind.Feat_if;
        result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start) - 3;
        return true;
    }

    if (t.feature_count >= constants.MaxFeatureDepth) {
        t.error(result, "feature nesting too much");
        return true;
    }

    //t.skip_whitespace();
    t.cur++;    // just skip space

    bool enabled = false;
    Action act = Char_lookup[*t.cur];
    switch (act) {
    case INVALID:
        t.error(result, "invalid char '%c'", *t.cur);
        return true;
    case IDENT_OR_KEYWORD: fallthrough;
    case IDENT:
        if (t.parse_feature(result, &enabled)) return true;
        break;
    case DIGIT:
        if (*t.cur != '0') enabled = true;
        t.cur++;
        break;
    case EOF:
        t.cur--;
        t.error(result, "expected feature");
        return true;
    default:
        t.error(result, "invalid feature value");
        return true;
    }

    Feature* next = &t.feature_stack[t.feature_count];
    next.is_if = true;
    next.enabled = enabled;
    t.feature_count++;
    return false;
}

fn bool Tokenizer.parse_feature(Tokenizer* t, Token* result, bool* enabled) {
    const char* start = t.cur;
    while (Identifier_char[*t.cur]) t.cur++;

    usize len = cast<usize>(t.cur - start);
    if (len > constants.MaxFeatureName) {
        t.error(result, "feature name too long (max %d chars)", constants.MaxFeatureName);
        return true;
    }

    char[constants.MaxFeatureName+1] name;
    string.memcpy(name, start, len);
    name[len] = 0;

    if (t.features.contains(name)) *enabled = true;
    return false;
}

fn bool Tokenizer.handle_else(Tokenizer* t, Token* result) {
    if (t.raw_mode) {
        result.kind = Kind.Feat_else;
        result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start) - 5;
        return true;
    }
    if (t.feature_count == 0) {
        t.error(result, "#else without #if");
        return true;
    }
    Feature* top = &t.feature_stack[t.feature_count-1];
    if (!top.is_if) {
        t.error(result, "#else in #else");
        return true;
    }
    top.is_if = false;
    top.enabled = !top.enabled;
    return false;
}

fn bool Tokenizer.handle_endif(Tokenizer* t, Token* result) {
    if (t.raw_mode) {
        result.kind = Kind.Feat_endif;
        result.loc = t.loc_start + cast<SrcLoc>(t.cur - t.input_start) - 6;
        return true;
    }
    if (t.feature_count == 0) {
        t.error(result, "#endif without #if/#else");
        return true;
    }
    //Feature* top = &t.feature_stack[t.feature_count-1];
    t.feature_count--;
    return false;
}

fn bool Tokenizer.skip_feature(Tokenizer* t, Token* result) {
    while (1) {
        Action act = Char_lookup[*t.cur];
        switch (act) {
        case INVALID:
            t.cur++;
            break;
        case NEWLINE:
            t.cur++;
            t.line_start = t.cur;
            break;
        case DQUOTE:
            t.skip_string_literal();
            break;
        // TODO handle block/line comments (could be weird stuff inside)
        case POUND:
            if (t.lex_feature_cmd(result)) return true;
            if (t.is_enabled()) return false;
            break;
        case EOF:
            t.cur--;
            Feature* top = &t.feature_stack[t.feature_count-1];
            t.error(result, "un-terminated #%s", top.is_if ? "if" : "else");
            return true;
        default:
            t.cur++;
            break;
        }
    }
    return false;
}

fn void Tokenizer.skip_string_literal(Tokenizer* t) {
    t.cur++;

    while (1) {
        switch (*t.cur) {
        case 0:
            return;
        case '\r':
            t.cur++;
            return;
        case '\n':
            return;
        case '"':
            t.cur++;
            return;
        default:
            t.cur++;
            break;
        }
    }
}

fn bool Tokenizer.is_multi_string(Tokenizer* t) {
    // skip whitespace/newlines, return true if first other char is "
    const char* c = t.cur;
    while (1) {
        switch (*c) {
        case '\t':  fallthrough;
        case '\n':  fallthrough;
        case '\r':  fallthrough;
        case ' ':
            c++;
            break;
        case '"':
            return true;
        default:
            return false;
        }

    }
    return false;
}

fn bool Tokenizer.skip_to_next_string(Tokenizer* t, Token* result) {
    while (1) {
        switch (*t.cur) {
        case '\t':
           t.cur++;
           break;
        case '\n':
            t.cur++;
            t.line_start = t.cur;
            break;
        case '\r':
            t.cur++;
            if (*t.cur != '\n') {
                t.error(result, "unexpected char 0x%02X", *t.cur);
                return false;
            }
            t.cur++;
            break;
        case ' ':
            t.cur++;
            break;
        case '"':
            return true;
        }

    }
    return true;
}

