/* Copyright 2022-2025 Bas van den Berg
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

module ir_context;

import bit_array;
import index_list;
import ir_copy_list local;
import ir_inserter;
import ir local;
import ir_lookup_table;
import ir_rev_list local;
import ir_slot_collector local;
import ir_slot_values local;
import string_pool;
import usage_counter;

import std;

type Tools struct {
    ir_lookup_table.Table conversion;
    SlotValues slot_values;
    SlotCollector collector;
    RevList revlist;
    ir_inserter.Inserter inserter;
    bit_array.BitArray active_blocks;
    CopyList copies;
    usage_counter.Counter usage;

    // for printing
    bool print_all;
    const void* arg1;   // Context*

    // change per function
    const void* arg2;   // Symbol*
    FunctionInfo* fi;   // no ownership

}
static_assert(808, sizeof(Tools));

fn void Tools.init(Tools* t, const void* arg1, bool print) {
    t.conversion.init(64);
    t.slot_values.create();
    t.collector.create();
    t.revlist.create(256);
    t.inserter.create();
    t.copies.init(1024);
    t.usage.init(1024);
    t.print_all = print;
    t.arg1 = arg1;
    t.arg2 = nil;
}

fn void Tools.free(Tools* t) {
    t.usage.free();
    t.copies.free();
    t.inserter.free();
    t.revlist.free();
    t.collector.free();
    t.slot_values.free();
    t.conversion.free();
}

fn void Tools.print_func(const Tools* t, const char* label) {
    const Context* c = t.arg1;
    c.print_function(t.arg2, t.fi, label);
}

fn u32 getSlotName(u32 slot) {
    // see Context.create()
    return 4 + slot*4;
}

type Builder struct {
    u32 slot_idx;
    u32 num_scopes;
    SymbolId cur_func;
    SymbolId cur_global;
    BlockId cur_block;
    u32 blk_start_instr;    // used to note starting instruction
    bool block_terminated;
    bool in_block;

    // only used during function generation
    index_list.List block_order;
    FunctionInfo* tmp_info;
}

fn void Builder.init(Builder* b) {
    b.block_order.init(64);
    b.tmp_info = nil;
}

fn void Builder.free(Builder* b) {
    if (b.tmp_info) b.tmp_info.free();
    b.block_order.free();
}

public type Context struct @(opaque) {
    // context stuff
    string_pool.Pool* pool;
    ConstantList constants;
    SymbolList symbols;
    InitValueList init_values;

    Builder b;

    // used during conversion of IR -> ASM
    Tools tools;

    bool single_thread;

    // TODO make full member if include bug is solved in bootstrap
    WorkQueue* queue;
}

public fn Context* create(bool print) {
    Context* c = std.calloc(1, sizeof(Context));
    c.pool = string_pool.create(2*1024, 256);
    c.constants.init(128);
    c.symbols.init(128);
    c.init_values.init(128);
    //c.queue.init();
    c.queue = WorkQueue.create();
    c.single_thread = true;
    //c.single_thread = false;

    // pre-load pool with slot names
    for (u32 slot = 0; slot < SlotMax; slot++) {
        char[8] slot_name;
        // Result: starts at 4, then +4 each
        // Note: just 4,8,12,
        std.sprintf(slot_name, "s%d", slot);
        u32 idx = c.pool.addStr(slot_name, false);
    }

    c.b.init();

    c.tools.init(c, print);
    return c;
}

public fn void Context.free(Context* c) {
    c.queue.free();
    c.tools.free();
    for (u32 i=1; i<c.symbols.getCount(); i++) {
        const Symbol* s = c.symbols.get(i);
        if (s.is_function && s.f.info) {
            s.f.info.free();
        }
    }

    c.b.free();

    c.init_values.free();
    c.symbols.free();
    c.constants.free();
    c.pool.free();
    std.free(c);
}

public fn void Context.convert_functions(Context* c) {
    if (c.single_thread) return;    // already done

    c.queue.run(c, 0);
}

public fn SymbolId Context.addStringLiteral(Context* c, const char* name, const char* text, u32 size) {
#if DebugIr
    std.printf("addStringLiteral(%s)\n", text);
#endif
    SymbolId id = c.addGlobalVar(name, 1, false);
    u32 text_idx = c.pool.addStr(text, false);

    Symbol* s = c.symbols.get(id);
    s.g.init_value_idx = c.init_values.getCount();
    s.g.init_value_count = 1;

    InitValue* v = c.init_values.add();
    v.init(InitValueKind.Text, text_idx);
    return id;
}

public fn SymbolId Context.addGlobalVar(Context* c, const char* name, u32 align, bool is_external) {
    u32 name_idx = c.pool.addStr(name, false);
    SymbolId id = c.symbols.add(name_idx, false, align, is_external);
#if DebugIr
    std.printf("addGlobalVar(%s) id=%d external=%d\n", name, id, is_external);
#endif
    return id;
}

public fn SymbolId Context.addFunction(Context* c, const char* name, bool is_external) {
    u32 name_idx = c.pool.addStr(name, false);
    // TODO 4/8 bytes, ARCH
    SymbolId id = c.symbols.add(name_idx, true, 4, is_external);
#if DebugIr
    std.printf("addFunction(%s) id=%d external=%d\n", name, id, is_external);
#endif
    return id;
}

public fn void Context.startFunc(Context* c, SymbolId id) {
    Builder* b = &c.b;
#if DebugIr
    std.printf("startFunc(%d)  cur %d\n", id, b.cur_func);
#endif
    assert(b.tmp_info == nil);
    b.tmp_info = FunctionInfo.create(8, 16, 16);
    assert(b.cur_func == 0);
    b.cur_func = id;
    b.num_scopes = 0;
    b.slot_idx = 0;
}

public fn void Context.endFunc(Context* c) {
    Builder* b = &c.b;
#if DebugIr
    std.printf("endFunc() cur %d\n", b.cur_func);
#endif
    assert(b.num_scopes == 0);
    assert(b.cur_func);

    c.finalizeFunction(b.cur_func);

    b.cur_func = 0;
}

public fn void Context.startGlobal(Context* c, SymbolId id) {
    Builder* b = &c.b;
#if DebugIr
    std.printf("startGlobal(%d)  cur %d\n", id, b.cur_global);
#endif
    assert(b.cur_global == 0);
    b.cur_global = id;
    Symbol* s = c.symbols.get(b.cur_global);
    s.g.init_value_idx = c.init_values.getCount();
}

public fn void Context.endGlobal(Context* c) {
    Builder* b = &c.b;
#if DebugIr
    std.printf("endGlobal()  cur %d\n", b.cur_global);
#endif
    assert(b.cur_global);
    Symbol* s = c.symbols.get(b.cur_global);
    s.g.init_value_count = c.init_values.getCount() - s.g.init_value_idx;
    b.cur_global = 0;
}

public fn void Context.addInitZero(Context* c, u32 size) {
#if DebugIr
    std.printf("addInitZero()  %d\n", size);
#endif
    assert(size < 0x0FFFFFFF);
    assert(c.b.cur_global);
    InitValue* v = c.init_values.add();
    v.init(InitValueKind.Zero, size);
}

public fn void Context.addInitValueU8(Context* c, u8 value) {
    InitValue* v = c.init_values.add();
    v.init(InitValueKind.Byte, value);
}

public fn void Context.addInitValueU16(Context* c, u16 value) {
    InitValue* v = c.init_values.add();
    v.init(InitValueKind.Short, value);
}

public fn void Context.addInitValueU32(Context* c, u32 value) {
    InitValue* v = c.init_values.add();
    if (value < 0x0FFFFFFF) {
        v.init(InitValueKind.Word, value);
    } else {
        Constant constant = { .uvalue = value }
        u32 idx = c.constants.add(&constant);
        v.init(InitValueKind.Word2, idx);
    }
}

public fn void Context.addInitValueU64(Context* c, u64 value) {
    InitValue* v = c.init_values.add();
    if (value < 0x0FFFFFFF) {
        v.init(InitValueKind.Long, cast<u32>(value));
    } else {
        Constant constant = { .uvalue = value }
        u32 idx = c.constants.add(&constant);
        v.init(InitValueKind.Long2, idx);
    }
}

public fn void Context.addInitSymbol(Context* c, SymbolId id) {
    InitValue* v = c.init_values.add();
    v.init(InitValueKind.Symbol, id);
}

// size = strlen()
public fn void Context.addInitString(Context* c, const char* text, u32 size) {
    InitValue* v = c.init_values.add();
    u32 text_idx = c.pool.add(text, size, false);
    v.init(InitValueKind.Text, text_idx);
}

public fn void Context.setFunctionReturnType(Context* c, Type t) {
    c.b.tmp_info.setReturnType(t);
}

public fn Ref Context.addFuncArg(Context* c, Type t) {
    c.b.tmp_info.addArg(t);

    u32 idx = c.b.tmp_info.instructions.getCount();
    Instr* i = c.b.tmp_info.instructions.add();
    i.init0b(InstrKind.Param);
    Ref ref.init(RefKind.Temp, idx);
    return ref;
}

public fn BlockId Context.createBlock(Context* c, BlockKind kind) {
    BlockId id = c.b.tmp_info.blocks.add(kind);
#if DebugIr
    std.printf(" createBlock(%s) id=%d\n", kind.str(), id);
#endif
    return id;
}

public fn bool Context.isBlockTerminated(const Context* c) {
    return c.b.block_terminated;
}

// Note: blocks are not implemented in order! (can be nested statements)
public fn void Context.startBlock(Context* c, BlockId id) {
#if DebugIr
    Block* b = c.b.tmp_info.blocks.get(id);
    std.printf(" startBlock(%s.%d) cur %d\n", b.getKindName(), id, c.b.cur_block);
#endif
    assert(!c.b.in_block);
    c.b.in_block = true;
    c.b.block_order.add(id);
    c.b.cur_block = id;
    c.b.block_terminated = false;
    c.b.blk_start_instr = c.b.tmp_info.instructions.getCount();
}

public fn void Context.endBlock(Context* c) {
#if DebugIr
    std.printf(" endBlock()\n");
#endif
    if (!c.b.block_terminated) {
        // always close block with jmp to next block
        c.addJmpInstr(c.b.cur_block+1);
    }
    Block* b = c.b.tmp_info.blocks.get(c.b.cur_block);
    b.setInstructions(c.b.blk_start_instr, c.b.tmp_info.instructions.getCount() - c.b.blk_start_instr);
    c.b.cur_block = 0;
    c.b.in_block = false;
}

public fn BlockId Context.getCurBlock(const Context* c) {
    return c.b.cur_block;
}

public fn void Context.addJmpInstr(Context* c, BlockId dest) {
    assert(c.b.in_block);
    Block* b = c.b.tmp_info.blocks.get(c.b.cur_block);
#if DebugIr
    std.printf("  jmp(%s.%d)\n", b.getKindName(), dest);
#endif
    // destination blocks are stored inside Block, not jmp instr
    b.setDest(dest, 0);
    Ref ref.init(RefKind.JmpDest, 0);
    Instr* i = c.b.tmp_info.instructions.add();
    i.init1(InstrKind.Jmp, ref);
    c.b.block_terminated = true;
}

public fn void Context.addJmpIfInstr(Context* c, Ref cond, BlockId dest1, BlockId dest2) {
    assert(c.b.in_block);
    Block* b = c.b.tmp_info.blocks.get(c.b.cur_block);
#if DebugIr
    Block* d1 = c.b.tmp_info.blocks.get(dest1);
    Block* d2 = c.b.tmp_info.blocks.get(dest2);
    std.printf("  jmp_if %s.%d, %s.%d\n", d1.getKindName(), dest1, d2.getKindName(), dest2);
#endif
    b.setDest(dest1, dest2);
    Ref ref.init(RefKind.JmpDest, 0);
    Instr* i = c.b.tmp_info.instructions.add();
    i.init2(InstrKind.JmpIf, cond, ref);
    c.b.block_terminated = true;
}

public fn void Context.addRet0Instr(Context* c) {
#if DebugIr
    std.printf("  ret\n");
#endif
    assert(c.b.in_block);
    Instr* i = c.b.tmp_info.instructions.add();
    i.init0(InstrKind.Ret);
    c.b.block_terminated = true;
    Block* b = c.b.tmp_info.blocks.get(c.b.cur_block);
    b.end_block = 1;
}

public fn void Context.addRet1Instr(Context* c, Ref ref) {
#if DebugIr
    std.printf("  ret <val>\n");
#endif
    assert(c.b.in_block);
    Instr* i = c.b.tmp_info.instructions.add();
    i.init1(InstrKind.Ret, ref);
    c.b.block_terminated = true;
    Block* b = c.b.tmp_info.blocks.get(c.b.cur_block);
    b.end_block = 1;
}

public fn Ref Context.addLoadInstr(Context* c, Type t, Ref src) {
#if DebugIr
    std.printf("  load %s %s %d\n", t.str(), src.getKindName(), src.value);
#endif
    assert(c.b.in_block);

    Ref out.init(RefKind.Temp, c.b.tmp_info.instructions.getCount());

    InstrKind k;
    switch (t) {
    case None:
        assert(0);
        return out;
    case I8:
        k = InstrKind.Load1;
        break;
    case I16:
        k = InstrKind.Load2;
        break;
    case I32:
        k = InstrKind.Load4;
        break;
    case I64:
        k = InstrKind.Load8;
        break;
    case U8:
        k = InstrKind.Load1;
        break;
    case U16:
        k = InstrKind.Load2;
        break;
    case U32:
        k = InstrKind.Load4;
        break;
    case U64:
        k = InstrKind.Load8;
        break;
    case F32:
        k = InstrKind.Load4;
        break;
    case F64:
        k = InstrKind.Load8;
        break;
    }
    Instr* i = c.b.tmp_info.instructions.add();
    i.init1b(k, src);
    return out;
}

const InstrKind[elemsof(Type)] Type2Store = {
    [Type.I8]  = InstrKind.Store1,
    [Type.I16] = InstrKind.Store2,
    [Type.I32] = InstrKind.Store4,
    [Type.I64] = InstrKind.Store8,
    [Type.U8]  = InstrKind.Store1,
    [Type.U16] = InstrKind.Store2,
    [Type.U32] = InstrKind.Store4,
    [Type.U64] = InstrKind.Store8,
    [Type.F32] = InstrKind.Store4,
    [Type.F64] = InstrKind.Store8,
}

public fn void Context.addStoreInstr(Context* c, Type t, Ref src, Ref dest) {
#if DebugIr
    std.printf("  store %s  %s %d -> %s %d\n", t.str(),
        src.getKindName(), src.value,
        dest.getKindName(), dest.value);
#endif
    assert(c.b.in_block);
    Instr* i = c.b.tmp_info.instructions.add();
    assert (t != Type.None);
    InstrKind k = Type2Store[t];
    i.init2(k, src, dest);
}

public fn Ref Context.addBinaryInstr(Context* c, InstrKind k, Ref left, Ref right) {
#if DebugIr
    std.printf("  binary Instr %s (%s %d, %s %d) \n", k.str(),
        left.getKindName(), left.value,
        right.getKindName(), right.value);
#endif
    Ref out.init(RefKind.Temp, c.b.tmp_info.instructions.getCount());

    Instr* i = c.b.tmp_info.instructions.add();
    i.init2b(k, left, right);
    return out;
}

public fn Ref Context.addCallInstr(Context* c, Ref name, const Ref* args, u32 num_args, bool has_result, bool noreturn) {
#if DebugIr
    std.printf("  call %s%d\n", name.getKindName(), name.value);
#endif
    for (u32 i = 0; i < num_args; i++) {
        Instr* ii = c.b.tmp_info.instructions.add();
        ii.init1(InstrKind.Arg, args[i]);
    }

    Ref out.init(RefKind.Temp, c.b.tmp_info.instructions.getCount());

    Instr* i = c.b.tmp_info.instructions.add();
    if (has_result) {
        i.init1b(InstrKind.Call, name);
    } else {
        i.init1(InstrKind.Call, name);
    }
    if (noreturn) {
        Block* b = c.b.tmp_info.blocks.get(c.b.cur_block);
        b.end_block = 1;
        c.b.block_terminated = true;
    }
    return out;
}

// Temp only for 2 refs, could be more
public fn Ref Context.addPhi2Instr(Context* c, BlockId b1, Ref r1, BlockId b2, Ref r2) {
#if DebugIr
    std.printf("  phi2  %d, %d\n", b1, b2);
#endif
    Ref out.init(RefKind.Temp, c.b.tmp_info.instructions.getCount());

    Instr* i = c.b.tmp_info.instructions.add();
    i.initPhi(c.b.tmp_info.phis.getCount(), 2);

    Block* blk = c.b.tmp_info.blocks.get(b1);
    blk.phi_source = 1;
    blk = c.b.tmp_info.blocks.get(b2);
    blk.phi_source = 1;

    c.b.tmp_info.phis.add(out.value, b1, r1);
    c.b.tmp_info.phis.add(out.value, b2, r2);
    return out;
}

public fn Ref Context.addStackSlot(Context* c, u32 align, Ref size) {
#if DebugIr
    std.printf("  slot (%d)\n", c.b.slot_idx);
#endif
    u32 idx = c.b.slot_idx;
    c.b.slot_idx++;
    assert(c.b.slot_idx < 65536); // to fit in u16
    // TODO use Temp (or convert after SSA creation)
    //Ref out.init(RefKind.Temp, c.b.tmp_info.instructions.getCount());
    Ref out.init(RefKind.Slot, idx);
    Instr* i = c.b.tmp_info.instructions.add();

    InstrKind kind;
    switch (align) {
    case 1:
        kind = InstrKind.Alloc1;
        break;
    case 2:
        kind = InstrKind.Alloc2;
        break;
    case 4:
        kind = InstrKind.Alloc4;
        break;
    case 8:
        kind = InstrKind.Alloc8;
        break;
    default:
        //std.printf("WARN: implement other alignment (%d)\n", align);
        kind = InstrKind.Alloc8;
        break;
    }
    i.init1b(kind, size);
    return out;
}

public fn Ref Context.addIntegerConstant(Context* c, i64 size) {
#if DebugIr
    std.printf("  integer (%d)\n", size);
#endif
    // if signed value fits in 27 bits, store it in Ref directly
    const i32 min_27bits = -0x3FFFFFF-1;
    const i32 max_27_bits = 0x3FFFFFF;
    Ref ref;
    if (size >= min_27bits && size <= max_27_bits) {
        ref.init(RefKind.Value, cast<u32>(size));
    } else {
        Constant constant = { .ivalue = size }
        u32 idx = c.constants.add(&constant);
        ref.init(RefKind.Integer, idx);
    }
    return ref;
}

public fn void Context.addComment(Context* c, const char* text) {
    FunctionInfo* fi = c.b.tmp_info;
    u32 idx = c.pool.addStr(text, false);
    Ref out.init(RefKind.Temp, fi.instructions.getCount());
    Instr* i = fi.instructions.add();
    Ref ref.init(RefKind.Text, idx);
    i.init1(InstrKind.Comment, ref);
}

public fn CaseId Context.addSwitchInstr(Context* c, Ref cond, BlockId join_blk, u32 num_cases) {
#if DebugIr
    std.printf("  switch (join %d, %d cases)\n", join_blk, num_cases);
#endif
    CaseId case_id = c.b.tmp_info.cases.reserve(num_cases);

    assert(c.b.in_block);
    Instr* i = c.b.tmp_info.instructions.add();
    Ref join_ref.init(RefKind.Block, join_blk);
    i.init2(InstrKind.Switch, cond, join_ref);
    c.b.block_terminated = true;
    Block* b = c.b.tmp_info.blocks.get(c.b.cur_block);
    b.end_with_switch = 1;
    b.setDest(case_id, num_cases);
    return case_id;
}

public fn void Context.setCase(Context* c, CaseId case_id, u32 value, BlockId blk_id) {
#if DebugIr
    std.printf("  case (%d) value %d blk %d\n", case_id, value, blk_id);
#endif
    c.b.tmp_info.cases.set(case_id, value, blk_id);
}

fn void Context.finalizeFunction(Context* c, SymbolId id) {
    // prune unused blocks and flatten blocks with only a jmp instruction
    Tools* t = &c.tools;
    Symbol* symbol = c.symbols.get(id);
    FunctionInfo* fi = c.b.tmp_info;

    t.arg2 = symbol;
    t.fi = fi;

    u32 num_blocks = fi.blocks.getCount();
    fi.num_slots = cast<u16>(c.b.slot_idx);

    //const char* name = c.pool.idx2str(symbol.name);

    //dump_function(fi, name);
    if (t.print_all) t.print_func("after generation");
    // prune unused and empty blocks, possible convert jmp_if to jmp
    checkDest(fi, 0);

    if (t.print_all) t.print_func("after check dest");

    // TODO use Builder 2nd BlockList here (pass as well)
    t.reorder_blocks(fi, &c.b.block_order);
    c.b.block_order.clear();

    symbol.f.info = fi;
    c.b.tmp_info = nil;

    // TODO can be multi-threaded after this point (ready for inlining)
    if (c.single_thread) {
        t.convert_fn();
    } else {
        c.queue.add(fi);
    }
}

fn void Tools.convert_fn(Tools* t) {
    FunctionInfo* fi = t.fi;
    if (t.print_all && fi.blocks.getCount() > 1) t.print_func("after reorder");
    //t.generate_graphviz(fi);

    // MULTI-THREAD: need to pre-alloc names for Slots (S0, S1, etc), since pool access needs to be read-only

    // NOTE: cannot have outstanding inserts which converting switches!
    bool changed = t.convert_switches();
    if (changed && t.print_all) t.print_func("after convert switch");
    //t.print_function(symbol, fi, "BEFORE collector fill");

    t.createSSA();
    //t.inserter.dump();

    //if (fi.blocks.getCount() > 1 && t.print_all) t.print_func("after create SSA");

    if (t.inserter.needsFixup()) {
        t.fixup_function();
        //if (t.print_all) t.print_func("after fixup");
    }
    if (fi.blocks.getCount() > 1 && t.print_all) t.print_func("after create SSA");
    //t.print_function(symbol, fi, "AFTER fixup");

    t.eliminateCopies();
    if (t.print_all) t.print_func("after eliminate copies");

    //t.propagateConstants();
    //if (t.print_all) t.print_function(symbol, fi, "after propagate constants");
    t.removeUnused();
    //if (print) t.print_func("after remove unused");

    //t.propagateConstants();

    t.removeNone();
    if (t.print_all) t.print_func("after remove none");

    t.allocateRegisters(fi);

    if (t.inserter.needsFixup()) t.fixup_function();
    if (t.print_all) t.print_func("after register allocation + phi-removal");

    // generate Instruction
    // ..
}

fn bool empty_block(const Block* b, const InstrList* instructions) {
    // empty means only a jump
    if (b.instr.count == 1) return true;
    if (b.instr.count == 2) {
        Instr* instr = instructions.get(b.instr.start);
        if (instr.getKind() == InstrKind.Comment) return true;

        instr = instructions.get(b.instr.start+1);
        if (instr.getKind() == InstrKind.Comment) return true;
    }
    return false;
}

// uses tmp_info! TODO could also just use cur_info (points to current)
fn BlockId checkDest(FunctionInfo* fi, BlockId id) {
    Block* b = fi.blocks.get(id);

    if (b.checked) {
        if (b.used) return id;  // avoid circular loops
        assert(!b.end_with_switch);
        return b.dests[0];
    }
    b.checked = true;

    if (b.end_with_switch) {
        b.used = true;
        CaseId case_id = b.dests[0];
        u32 num_cases = b.dests[1];
        for (u32 i=0; i<num_cases; i++) {
            Case* cs = fi.cases.get(case_id+i);
            BlockId new_blk = checkDest(fi, cs.block);
            cs.block = new_blk;
        }

        // update join blk
        u32 instr_idx = b.instr.start + b.instr.count - 1;
        Instr* switch_instr = fi.instructions.get(instr_idx);
        assert(switch_instr.isSwitch());
        Ref* join_ref = &switch_instr.args[1];
        join_ref.value = checkDest(fi, join_ref.value);
        return id;
    }

    if (b.dests[0] == 0 && b.dests[1] == 0) {   // last one
        b.used = true;
        return id;
    }

    if (!b.phi_source && id != 0 && empty_block(b, &fi.instructions)) {
        BlockId new_blk = checkDest(fi, b.dests[0]);
        if (new_blk == id) {
            b.used = true;
            b.dests[0] = id;    // create circular loop
        } else {
            b.used = false;
            b.dests[0] = new_blk;   // set for next queries
        }
        return new_blk;
    }

    b.used = true;
    if (b.dests[0]) {
        b.dests[0] = checkDest(fi, b.dests[0]);
    }
    if (b.dests[1]) {
        b.dests[1] = checkDest(fi, b.dests[1]);
    }

    if (b.dests[0] == b.dests[1]) {
        // both jumps go to same dest, convert cmp + jmp_if -> jmp
        Instr* last = fi.instructions.get(b.instr.start + b.instr.count -1);
        Ref ref.init(RefKind.JmpDest, id);
        last.init1(InstrKind.Jmp, ref);
        b.dests[1] = 0;
        // unroll all unused temps -> after re-writing?
    }

    return id;
}


// Can only be used after switch-instructions have been converted
fn void Tools.markUsedBlocks(Tools* t, FunctionInfo* fi) {
    u32 num_blocks = fi.blocks.getCount();
    Block* blocks = fi.blocks.get(0);

    for (u32 i=0; i<num_blocks; i++) {
        blocks[i].checked = false;
        blocks[i].used = blocks[i].phi_source;
    }

    BlockId* blocks2 = std.malloc(num_blocks * sizeof(BlockId));
    //rpo.num_blocks = num_blocks;

    blocks2[0] = 0; // add start block to todo-list
    blocks[0].checked = true;
    blocks[0].used = true;
    u32 head = 1;   // insert point
    u32 tail = 0; // check point

    //printf("find unused: (%d blocks)\n", num_blocks);
    while (head != tail) {
        BlockId blk_id = blocks2[tail];
        //printf("  %d/%d  B%d\n", tail, head, blk_id);

        Block* b = &blocks[blk_id];

        for (u32 d = 0; d < 2; d++) {
            BlockId dest_id = b.dests[d];
            assert(dest_id < num_blocks);
            if (!dest_id) break;

            Block* dest = &blocks[dest_id];
            if (!dest.checked) {
                //printf("   add %d\n", dest_id);
                blocks2[head++] = dest_id;
                dest.checked = true;
                dest.used = true;
            }
        }
        tail++;
    }
#if 0
    printf("USED: \n");
    for (u32 i = 0; i < num_blocks; i++) printf("  B%d  used %d\n", i, blocks[i].used);
#endif
    std.free(blocks2);
}

// NOTE: also removes unused blocks, clears instructions in removed blocks
fn void Tools.reorder_blocks(Tools* t, FunctionInfo* fi, const index_list.List* block_order) {
    const u32* order = block_order.getFrom(0);

    u32 num_blocks = block_order.getCount();
    assert(num_blocks == fi.blocks.getCount());
    BlockList list2.init(num_blocks);
    Block* blocks1 = fi.blocks.get(0);

    t.conversion.clear(num_blocks);

    u32 blk_count = 0;
    for (u32 i=0; i<num_blocks; i++) {
        BlockId blk_id = order[i];
        const Block* old = &blocks1[blk_id];
        if (!old.used) { // clear instructions of unused blocks
            Instr* instrs = fi.instructions.get(old.instr.start);
            for (u32 j=0; j<old.instr.count; j++) instrs[j].clear();
            continue;
        }
        list2.copy(old);
        t.conversion.set(blk_id, blk_count);
        blk_count++;
    }

    // convert block dests (old -> new)
    Block* blocks2 = list2.get(0);
    assert(t.conversion.get(0) == 0);   // block 0 should never move
    for (u32 i = 0; i < blk_count; i++) {
        Block* b = &blocks2[i];
        if (b.end_with_switch) {
            CaseId case_id = b.dests[0];
            u32 num_cases = b.dests[1];
            for (u32 j=0; j<num_cases; j++) {
                Case* cs = fi.cases.get(case_id+j);
                cs.block = t.conversion.get(cs.block);
            }
            //u32 join_blk = i.args[1].value;
            // update block id in switch instr.args[1], is last instruction (if not comment)
            u32 instr_idx = b.instr.start + b.instr.count - 1;
            Instr* switch_instr = fi.instructions.get(instr_idx);
            assert(switch_instr.isSwitch());
            Ref* join_ref = &switch_instr.args[1];
            join_ref.value = t.conversion.get(join_ref.value);
        } else {
            b.dests[0] = t.conversion.get(b.dests[0]);
            b.dests[1] = t.conversion.get(b.dests[1]);
        }
    }
    // also update block ids in phi clauses
    for (u32 i = 0; i < fi.phis.getCount(); i++) {
        PhiClause* pc = fi.phis.get(i);
        pc.src = t.conversion.get(pc.src);
    }

    // strip of empty instructions at end
    fi.instructions.prune();

    fi.blocks.swap(&list2);
    list2.free();
}


